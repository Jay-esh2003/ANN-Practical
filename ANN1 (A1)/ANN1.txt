import numpy as np
import matplotlib.pyplot as plt

# Activation functions
def sigmoid(x):
    return 1 / (1 + np.exp(-x))

def tanh(x):
    return np.tanh(x)

def relu(x):
    return np.maximum(0, x)

def softmax(x):
    e_x = np.exp(x - np.max(x))
    return e_x / e_x.sum()

# Input range
x = np.linspace(-10, 10, 100)

# Plotting
plt.figure(figsize=(10, 8))

plt.subplot(2, 2, 1)
plt.plot(x, sigmoid(x))
plt.title("Sigmoid")

plt.subplot(2, 2, 2)
plt.plot(x, tanh(x))
plt.title("Tanh")

plt.subplot(2, 2, 3)
plt.plot(x, relu(x))
plt.title("ReLU")

plt.subplot(2, 2, 4)
plt.plot(x, softmax(x))
plt.title("Softmax")

plt.tight_layout()
plt.show()

-------

import networkx as nx
import matplotlib.pyplot as plt

# Create a directed graph
graph = nx.DiGraph()

# Add input layer nodes
graph.add_node('Input 1', layer='input')
graph.add_node('Input 2', layer='input')

# Add output layer node
graph.add_node('Output 1', layer='output')

# Add edges with example weights connecting inputs to output
graph.add_edge('Input 1', 'Output 1', weight=0.5)
graph.add_edge('Input 2', 'Output 1', weight=0.8)

# Define positions for each node
pos = {
    'Input 1': (0, 0.5),
    'Input 2': (0, -0.5),
    'Output 1': (1, 0)
}

# Draw the graph
plt.figure(figsize=(6, 4))
nx.draw(graph, pos, with_labels=True, node_size=1000, node_color='skyblue', font_size=10, font_weight='bold', arrows=True)

# Draw edge labels (weights)
edge_labels = nx.get_edge_attributes(graph, 'weight')
nx.draw_networkx_edge_labels(graph, pos, edge_labels=edge_labels)

plt.title("Simple 2-Layer Neural Network")
plt.axis('off')  # Hide axes
plt.show()

# Print edge weights (optional)
print("Edge Weights:", edge_labels)